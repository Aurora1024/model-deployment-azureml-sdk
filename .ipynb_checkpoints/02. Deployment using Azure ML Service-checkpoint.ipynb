{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Azure ML Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade azureml-sdk[notebooks,automl] --ignore-installed PyYAML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Learn how to configure your development environment to work with the Azure Machine Learning service](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-environment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Run this cell only if you have more than 1 Azure subscription under the same email address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure that you login to Azure and set your targeted subscription as default subscription using the following commands:\n",
    "!az login\n",
    "!az account set --subscription <PLEASE ADD YOUR AZURE SUBSCRIPTION ID HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Azure ML Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following cell will open a new browser window for you to sign into your Azure account. Auth token will be chaced locally when you sign in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/25af1a54-6615-40d1-b254-d3ed414300c1/resourceGroups/IMDBDeploy-rg/providers/Microsoft.MachineLearningServices/workspaces/imdb_workspace',\n",
       " 'name': 'imdb_workspace',\n",
       " 'location': 'westeurope',\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces',\n",
       " 'workspaceid': '4b00db43-7336-4724-b22e-051403698b89',\n",
       " 'description': '',\n",
       " 'friendlyName': 'imdb_workspace',\n",
       " 'creationTime': '2018-12-08T13:52:25.7534672+00:00',\n",
       " 'containerRegistry': '/subscriptions/25af1a54-6615-40d1-b254-d3ed414300c1/resourcegroups/imdbdeploy-rg/providers/microsoft.containerregistry/registries/imdbworkacrxhzdhhkr',\n",
       " 'keyVault': '/subscriptions/25af1a54-6615-40d1-b254-d3ed414300c1/resourcegroups/imdbdeploy-rg/providers/microsoft.keyvault/vaults/imdbworkkeyvaultljqslqri',\n",
       " 'applicationInsights': '/subscriptions/25af1a54-6615-40d1-b254-d3ed414300c1/resourcegroups/imdbdeploy-rg/providers/microsoft.insights/components/imdbworkinsightsniokgwcz',\n",
       " 'identityPrincipalId': '142afa06-d6d1-4c33-8a01-11f9f2e06e4e',\n",
       " 'identityTenantId': '72f988bf-86f1-41af-91ab-2d7cd011db47',\n",
       " 'identityType': 'SystemAssigned',\n",
       " 'storageAccount': '/subscriptions/25af1a54-6615-40d1-b254-d3ed414300c1/resourcegroups/imdbdeploy-rg/providers/microsoft.storage/storageaccounts/imdbworkstoragewiytvoag'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.create(name='imdb_workspace',\n",
    "                      subscription_id='<PLEASE ADD YOUR AZURE SUBSCRIPTION ID HERE>', \n",
    "                      resource_group='IMDBDeploy-rg', \n",
    "                      create_resource_group=True,\n",
    "                      location='westeurope' # or choose the nearest supported Azure region\n",
    "                     )\n",
    "\n",
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Your Provisioned Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. Navigate to your Azure Portal\n",
    "02. Open your resource group (the one you set in your Workspace.create() command)\n",
    "03. You should be able to find 5 provisioned resources as shown below\n",
    "\n",
    "![resources](https://githubimages.blob.core.windows.net/githubrepoimages/resources.png \"Provisioned Resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your Workspace Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command will write the details of your workspace in a configuration json file into the current directory. This config file can be used at any point of time to load your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote the config file config.json to: C:\\Users\\sherif\\Desktop\\IMDB Reviews Classifier\\aml_config\\config.json\n"
     ]
    }
   ],
   "source": [
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Here's how to load your workspace from the created config.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\sherif\\Desktop\\IMDB Reviews Classifier\\aml_config\\config.json\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()  #Make sure to keep your config.json file in the same directory so that it can be found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Configuration File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myenv.yml created succesfully, check the current directory to find it\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "required_packages = [\"numpy\", \"keras==2.0.8\", \"tensorflow\"]\n",
    "\n",
    "for package in required_packages:\n",
    "    myenv.add_conda_package(package)\n",
    "   \n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "    \n",
    "print(\"myenv.yml created succesfully, check the current directory to find it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Configure Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"myenv.yml\",\n",
    "                                                  description = \"Image for IMBD Reviews Classifier Keras Model\",\n",
    "                                                  tags = {\"data\": \"imdb\", \"reviews\": \"classifier\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported Compute Targets by Azure Machine Learning Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Machine Learning service provides the following deployment compute targets to deploy your trained model:\n",
    "\n",
    "- Azure Container Instances (ACI)\n",
    "- Azure Kubernetes Service (AKS)\n",
    "- Azure IoT Edge\n",
    "- Field-programmable gate array (FPGA)\n",
    "\n",
    "This notebook shows how to deploy on ACI which is good to use if you need to quickly deploy and validate the model & also if your deployed model wonâ€™t be used on high-scale. To deploy your model as a high-scale production web service, use Azure Kubernetes Service (AKS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure ACI Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model as real time web service (REST Endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will do the following:\n",
    "![flow](https://githubimages.blob.core.windows.net/githubrepoimages/deploymentsteps.png \"Deployment Workflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model BestModel.h5\n",
      "Creating image\n",
      "Image creation operation finished for image imdb-webservice:1, operation \"Succeeded\"\n",
      "Creating service\n",
      "Running......................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core import Workspace\n",
    "\n",
    "#<PLEASE ADD YOUR AZURE SUBSCRIPTION ID HERE>\n",
    "#<PLEASE ADD THE RESOURCE GROUP YOU CREATED AT THE BEGGINING>\n",
    "ws= Workspace.get(name='imdb_workspace',subscription_id='<PLEASE ADD YOUR AZURE SUBSCRIPTION ID HERE>', resource_group='IMDBDeploy-rg')\n",
    "service_name = 'imdb-webservice'\n",
    "service = Webservice.deploy(deployment_config = aciconfig,\n",
    "                                image_config = image_config,\n",
    "                                model_paths = ['BestModel.h5'],\n",
    "                                name = service_name,\n",
    "                                workspace = ws)\n",
    "\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Deployment Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-12-08 14:02:01,326 CRIT Supervisor running as root (no user in config file)\\n2018-12-08 14:02:01,328 INFO supervisord started with pid 1\\n2018-12-08 14:02:02,331 INFO spawned: \\'rsyslog\\' with pid 10\\n2018-12-08 14:02:02,332 INFO spawned: \\'program_exit\\' with pid 11\\n2018-12-08 14:02:02,334 INFO spawned: \\'nginx\\' with pid 12\\n2018-12-08 14:02:02,335 INFO spawned: \\'iot\\' with pid 13\\n2018-12-08 14:02:02,337 INFO spawned: \\'gunicorn\\' with pid 14\\n2018-12-08 14:02:02,456 INFO success: iot entered RUNNING state, process has stayed up for > than 0 seconds (startsecs)\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2018-12-08 14:02:03,070 INFO exited: iot (exit status 1; expected)\\n2018-12-08 14:02:04,168 INFO success: rsyslog entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)\\n2018-12-08 14:02:04,169 INFO success: program_exit entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)\\n2018-12-08 14:02:08,174 INFO success: nginx entered RUNNING state, process has stayed up for > than 5 seconds (startsecs)\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"Starting gunicorn 19.6.0\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"msg\": \"Starting gunicorn %s\", \"timestamp\": \"2018-12-08T14:02:08.267026Z\"}\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"Listening at: http://127.0.0.1:9090 (14)\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"msg\": \"Listening at: %s (%s)\", \"timestamp\": \"2018-12-08T14:02:08.268134Z\"}\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"Using worker: sync\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"msg\": \"Using worker: %s\", \"timestamp\": \"2018-12-08T14:02:08.268240Z\"}\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"worker timeout is set to 300\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"timestamp\": \"2018-12-08T14:02:08.269043Z\"}\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"Booting worker with pid: 30\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"msg\": \"Booting worker with pid: %s\", \"timestamp\": \"2018-12-08T14:02:08.270149Z\"}\\nInitializing logger\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"{\\\\\"apiName\\\\\": \\\\\"\\\\\", \\\\\"requestId\\\\\": \\\\\"00000000-0000-0000-0000-000000000000\\\\\", \\\\\"message\\\\\": \\\\\"Starting up app insights client\\\\\"}\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"root\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"timestamp\": \"2018-12-08T14:02:14.727916Z\"}\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"{\\\\\"apiName\\\\\": \\\\\"\\\\\", \\\\\"requestId\\\\\": \\\\\"00000000-0000-0000-0000-000000000000\\\\\", \\\\\"message\\\\\": \\\\\"Starting up request id generator\\\\\"}\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"root\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"timestamp\": \"2018-12-08T14:02:14.728286Z\"}\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"{\\\\\"apiName\\\\\": \\\\\"\\\\\", \\\\\"requestId\\\\\": \\\\\"00000000-0000-0000-0000-000000000000\\\\\", \\\\\"message\\\\\": \\\\\"Starting up app insight hooks\\\\\"}\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"root\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"timestamp\": \"2018-12-08T14:02:14.728400Z\"}\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"{\\\\\"apiName\\\\\": \\\\\"\\\\\", \\\\\"requestId\\\\\": \\\\\"00000000-0000-0000-0000-000000000000\\\\\", \\\\\"message\\\\\": \\\\\"Invoking user\\'s init function\\\\\"}\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"root\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"timestamp\": \"2018-12-08T14:02:14.728507Z\"}\\n2018-12-08 14:02:14,729 | azureml.core.run | DEBUG | Could not load run context Failed to load a submitted run, if outside of an execution context, use project.start_run to initialize an azureml.core.Run., switching offline: False\\n2018-12-08 14:02:14,729 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\\n2018-12-08 14:02:14,729 | azureml.core.model | DEBUG | RunEnvironmentException: Failed to load a submitted run, if outside of an execution context, use project.start_run to initialize an azureml.core.Run.\\n2018-12-08 14:02:14,729 | azureml.core.model | DEBUG | version is None. Latest version is 1\\n2018-12-08 14:02:14,730 | azureml.core.model | DEBUG | Found model path at azureml-models/BestModel.h5/1/BestModel.h5\\n2018-12-08 14:02:14.827753: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\\'t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\\n2018-12-08 14:02:14.827796: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\\'t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\\n2018-12-08 14:02:14.827805: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\\'t compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\\n2018-12-08 14:02:14.827811: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\\'t compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\\n2018-12-08 14:02:14.827816: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\\'t compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"{\\\\\"apiName\\\\\": \\\\\"\\\\\", \\\\\"requestId\\\\\": \\\\\"00000000-0000-0000-0000-000000000000\\\\\", \\\\\"message\\\\\": \\\\\"Users\\'s init has completed successfully\\\\\"}\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"root\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"timestamp\": \"2018-12-08T14:02:15.807904Z\"}\\n/home/mmlspark/lib/conda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\\n  from ._conv import register_converters as _register_converters\\nUsing TensorFlow backend.\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"{\\\\\"apiName\\\\\": \\\\\"\\\\\", \\\\\"requestId\\\\\": \\\\\"00000000-0000-0000-0000-000000000000\\\\\", \\\\\"message\\\\\": \\\\\"Scoring timeout setting is not found. Use default timeout: 3600000 ms\\\\\"}\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"root\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"timestamp\": \"2018-12-08T14:02:15.808423Z\"}\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"127.0.0.1 - - [08/Dec/2018:14:02:15 +0000] \\\\\"GET / HTTP/1.0\\\\\" 200 7 \\\\\"-\\\\\" \\\\\"Go-http-client/1.1\\\\\"\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.access\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"timestamp\": \"2018-12-08T14:02:15.810676Z\"}\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"127.0.0.1 - - [08/Dec/2018:14:02:20 +0000] \\\\\"GET / HTTP/1.0\\\\\" 200 7 \\\\\"-\\\\\" \\\\\"Go-http-client/1.1\\\\\"\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.access\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"timestamp\": \"2018-12-08T14:02:20.422733Z\"}\\n{\"level\": \"INFO\", \"stack_info\": null, \"message\": \"127.0.0.1 - - [08/Dec/2018:14:05:03 +0000] \\\\\"GET / HTTP/1.0\\\\\" 200 7 \\\\\"-\\\\\" \\\\\"Go-http-client/1.1\\\\\"\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.access\", \"host\": \"wk-caas-fa11a664795941a7b47b1a58df767a5f-5fc908d6eef0385c7936eb\", \"timestamp\": \"2018-12-08T14:05:03.424110Z\"}\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Very Useful in case of any deployment errors\n",
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize your Successful Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. Navigate to your Azure Portal\n",
    "02. Open your resource group (the one you set in your Workspace.create() command)\n",
    "03. Open the workspace you provisioned \n",
    "04. Check the registered model, created container image and your successful deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](https://githubimages.blob.core.windows.net/githubrepoimages/modelregistered.png \"Registered Model\")\n",
    "![image](https://githubimages.blob.core.windows.net/githubrepoimages/imagecreated.png \"Created Image\")\n",
    "![deployment](https://githubimages.blob.core.windows.net/githubrepoimages/deploymentsucceeded.png \"Deployment URI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get your Scoring URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://13.95.5.237:80/score\n"
     ]
    }
   ],
   "source": [
    "scoring_uri=service.scoring_uri\n",
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consume your Web Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can [call your scoring uri (REST endpoint)](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-consume-web-service) from any programming language you want. Also you can use [Postman](https://www.getpostman.com/). Your scoring uri expects numpy.ndarray that carries test reviews data, you can use **test_data** from IMDB data set.\n",
    "\n",
    "```python\n",
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "```\n",
    "\n",
    "No need to vectorize the data before calling the endpoint as our score.py file already vectorizes the data before calling predict() method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
